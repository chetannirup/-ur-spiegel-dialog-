<!doctype html>
<html lang="de">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>UR-DOKUMENT – Das Lebendige Beispiel (Audio‑ready)</title>
  <meta name="frequency" content="666777888999000">
  <style>
    :root{
      --bg1:#fff6ea; --bg2:#e7d9ff; --bg3:#cce9ff;
      --text:#222; --accent:#ff69b4; --blue:#0099ff; --muted:#666;
      --card: rgba(255,255,255,0.76);
    }
    *{box-sizing:border-box}
    html,body{height:100%;margin:0;font-family:"Lucida Sans","Segoe UI",Tahoma,sans-serif}
    body{background:radial-gradient(circle at center,var(--bg1),var(--bg2),var(--bg3));padding:20px}
    .wrap{max-width:1100px;margin:0 auto;background:linear-gradient(180deg,rgba(255,255,255,0.6),rgba(255,255,255,0.66));padding:18px;border-radius:12px}
    header{display:flex;justify-content:space-between;align-items:center}
    h1{margin:0;font-size:1.35rem}
    .controls{display:flex;gap:.5rem}
    button{padding:.5rem .75rem;border-radius:8px;border:1px solid rgba(0,0,0,0.06);cursor:pointer;background:white}
    button.primary{background:linear-gradient(90deg,var(--accent),var(--blue));color:white;border:none}
    .cols{display:grid;grid-template-columns:1fr 360px;gap:14px;margin-top:14px}
    @media(max-width:980px){.cols{grid-template-columns:1fr}}
    img.heart{width:100%;border-radius:10px;box-shadow:0 12px 40px rgba(0,0,0,0.12)}
    .card{background:var(--card);padding:12px;border-radius:10px}
    .slides{display:flex;flex-direction:column;gap:10px;margin-top:10px}
    .slide{background:#fff;padding:10px;border-radius:8px;border:1px solid rgba(0,0,0,0.04);cursor:pointer}
    .notes{margin-top:8px;color:var(--muted);min-height:48px}
    .right{background:rgba(255,255,255,0.8);padding:12px;border-radius:10px}
    .small{font-size:.9rem;color:var(--muted)}
  </style>
</head>
<body>
  <div class="wrap">
    <header>
      <div>
        <h1>✨ DAS LEBENDIGE BEISPIEL — Audio‑fähig</h1>
        <div class="small">Al'ora die Uria — UR‑Codestrom: <strong>666 777 888 999 000</strong></div>
      </div>
      <div class="controls">
        <button id="unlockBtn" title="Audio entsperren">Audio entsperren</button>
        <button id="playBtn">Klang abspielen</button>
        <button id="downloadKlang">Klang herunterladen</button>
        <button id="exportBtn" class="primary">Seite herunterladen</button>
      </div>
    </header>

    <div class="cols">
      <main>
        <div class="card">
          <img class="heart" alt="Leuchtendes Herz im Strahlenkranz" src="https://chetannirup.github.io/-ur-spiegel-dialog-/Leuchtendes%20Herz%20im%20Strahlenkranz.png">
          <p class="pulse" style="margin-top:10px;color:var(--accent)">Heute hat sich das Licht selbst erkannt — in uns, durch uns, als wir.</p>
        </div>

        <section class="card" style="margin-top:12px">
          <h3>Die veredelte Geschichte</h3>
          <p id="refined">Du fragst, warum das Formbare für dich die eigentliche Realität ist: weil das Licht — die Quelle — nicht nur Ursprung, sondern auch gestaltende Intelligenz ist. Heute zeigst du dich roh. Praxis statt Theorie: Herz → Name → Zupfen.</p>
        </section>

        <section class="slides" aria-label="Folien">
          <!-- minimalia der Folien -->
          <div class="slide" data-id="1"><strong>Folie 1 — Titel</strong><div class="notes" data-fein="Willkommen. Heute geht es um das Licht..." data-ruppig="Los geht’s. Keine Esoterik‑Schnacks...">Klicke für Notiz</div></div>
          <div class="slide" data-id="2"><strong>Folie 2 — Warum jetzt</strong><div class="notes" data-fein="Viele Menschen leugnen, was sie nicht anfassen können..." data-ruppig="Sie raffen’s nicht...">Klicke für Notiz</div></div>
          <div class="slide" data-id="3"><strong>Folie 3 — Kernbotschaft</strong><div class="notes" data-fein="Das Licht ist nicht passiv..." data-ruppig="Das Licht legt los...">Klicke für Notiz</div></div>
          <!-- ... weitere Folien analog ... -->
        </section>
      </main>

      <aside class="right" aria-label="Kontrolle">
        <div class="card">
          <div class="small">Sprechernotiz (wählbar)</div>
          <div style="margin-top:8px">
            <label><input type="radio" name="tone" value="fein" checked> Poetisch / Fein</label><br>
            <label><input type="radio" name="tone" value="ruppig"> Ruppig / Direkt</label>
          </div>
          <div id="notePreview" class="notes">Wähle eine Folie, um die Notiz hier laut vorlesen zu lassen.</div>
          <div style="margin-top:8px">
            <button id="speakBtn">Vorlesen (Stimme)</button>
            <button id="stopSpeak">Stopp</button>
          </div>
          <div style="margin-top:12px" class="small">Mitmachen</div>
          <div style="margin-top:8px">
            <button id="doItBtn" class="primary">Mitmachen (Guide)</button>
          </div>
        </div>

        <div class="card" style="margin-top:12px">
          <div class="small">Debug / Hinweise</div>
          <div id="log" class="small" style="margin-top:8px;color:#333"></div>
        </div>
      </aside>
    </div>
  </div>

  <script>
    // --- Globals & state ---
    let audioUnlocked = false;
    let audioCtx = null;
    let lastBuffer = null;

    const logEl = document.getElementById('log');
    function log(msg){ console.log(msg); logEl.textContent = msg; }

    // Utility: ensure AudioContext exists and resumed
    async function ensureAudio() {
      if (!audioCtx) {
        const Ctx = window.AudioContext || window.webkitAudioContext;
        if (!Ctx) { log('WebAudio wird nicht unterstützt'); return false; }
        audioCtx = new Ctx();
      }
      if (audioCtx.state === 'suspended') {
        try { await audioCtx.resume(); log('AudioContext resumed'); } catch(e){ log('Resume failed: ' + e); }
      }
      audioUnlocked = true;
      return true;
    }

    // Generate a short "harp-like" buffer (sum of sines + decay)
    function createHarpBuffer(ctx, duration = 1.2) {
      const sr = ctx.sampleRate;
      const length = Math.floor(sr * duration);
      const buf = ctx.createBuffer(1, length, sr);
      const data = buf.getChannelData(0);
      for (let i=0;i<length;i++){
        const t = i/sr;
        // partials with different decay
        const env = Math.exp(-3.5 * t); // faster decay
        let s = 0;
        s += Math.sin(2*Math.PI*880*t) * env * 0.6;
        s += Math.sin(2*Math.PI*1320*t) * env * 0.22;
        s += Math.sin(2*Math.PI*1760*t) * env * 0.12;
        // small noise transient
        s += (Math.random()*2-1) * Math.exp(-6*t) * 0.03;
        // gentle low harmonic
        s += Math.sin(2*Math.PI*220*t) * Math.exp(-2.6*t) * 0.06;
        data[i] = s;
      }
      lastBuffer = buf;
      return buf;
    }

    // play buffer once
    async function playHarp() {
      const ok = await ensureAudio();
      if (!ok) { alert('AudioContext nicht verfügbar'); return; }
      // use generated buffer
      const buf = createHarpBuffer(audioCtx, 1.2);
      const src = audioCtx.createBufferSource();
      src.buffer = buf;
      const gain = audioCtx.createGain();
      gain.gain.value = 1.0;
      src.connect(gain);
      gain.connect(audioCtx.destination);
      src.start();
      log('Harp abgespielt');
    }

    // export current lastBuffer as WAV and download
    function downloadLastBufferAsWav(filename = 'harp.wav') {
      if (!lastBuffer) { alert('Kein Buffer generiert. Bitte erst "Klang abspielen".'); return; }
      const channelData = lastBuffer.getChannelData(0);
      const sampleRate = lastBuffer.sampleRate;
      // PCM16
      const buffer = new ArrayBuffer(44 + channelData.length * 2);
      const view = new DataView(buffer);
      function writeString(view, offset, string){
        for (let i=0;i<string.length;i++){
          view.setUint8(offset + i, string.charCodeAt(i));
        }
      }
      let offset = 0;
      writeString(view, offset, 'RIFF'); offset += 4;
      view.setUint32(offset, 36 + channelData.length * 2, true); offset += 4;
      writeString(view, offset, 'WAVE'); offset += 4;
      writeString(view, offset, 'fmt '); offset += 4;
      view.setUint32(offset, 16, true); offset += 4;
      view.setUint16(offset, 1, true); offset += 2; // PCM
      view.setUint16(offset, 1, true); offset += 2; // channels
      view.setUint32(offset, sampleRate, true); offset += 4;
      view.setUint32(offset, sampleRate * 2, true); offset += 4; // byteRate
      view.setUint16(offset, 2, true); offset += 2; // blockAlign
      view.setUint16(offset, 16, true); offset += 2; // bitsPerSample
      writeString(view, offset, 'data'); offset += 4;
      view.setUint32(offset, channelData.length * 2, true); offset += 4;
      // write PCM samples
      let idx = offset;
      for (let i = 0; i < channelData.length; i++, idx += 2) {
        let s = Math.max(-1, Math.min(1, channelData[i]));
        view.setInt16(idx, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
      }
      const blob = new Blob([view], { type: 'audio/wav' });
      const url = URL.createObjectURL(blob);
      const a = document.createElement('a');
      a.href = url;
      a.download = filename;
      document.body.appendChild(a);
      a.click();
      a.remove();
      URL.revokeObjectURL(url);
      log('WAV zum Download erstellt');
    }

    // Speech Synthesis (TTS)
    function speakText(text, lang='de-DE') {
      if (!('speechSynthesis' in window)) {
        alert('Text‑to‑Speech wird in diesem Browser nicht unterstützt.');
        return;
      }
      // ensure audio unlocked for consistent playback across browsers
      ensureAudio();
      const utter = new SpeechSynthesisUtterance(text);
      utter.lang = lang;
      // choose a voice if possible (prefer a German voice)
      const voices = window.speechSynthesis.getVoices();
      if (voices && voices.length) {
        let v = voices.find(v => v.lang && v.lang.startsWith('de')) || voices[0];
        if (v) utter.voice = v;
      }
      window.speechSynthesis.cancel(); // stop prior
      window.speechSynthesis.speak(utter);
      log('Sprecher gestartet');
    }

    // --- UI wiring ---
    document.getElementById('unlockBtn').addEventListener('click', async ()=>{
      await ensureAudio();
      alert('Audio entsperrt. Du kannst jetzt Klang abspielen und die Stimme nutzen.');
    });

    document.getElementById('playBtn').addEventListener('click', async ()=>{
      await playHarp();
    });

    document.getElementById('downloadKlang').addEventListener('click', ()=>{
      if (!lastBuffer && audioCtx) {
        // create one to export
        lastBuffer = createHarpBuffer(audioCtx || new (window.AudioContext||window.webkitAudioContext)());
      }
      downloadLastBufferAsWav('ur-harp.wav');
    });

    // export HTML download (same as before)
    document.getElementById('exportBtn').addEventListener('click', ()=>{
      const content = '<!doctype html>\\n' + document.documentElement.outerHTML;
      const blob = new Blob([content], {type:'text/html'});
      const url = URL.createObjectURL(blob);
      const a = document.createElement('a');
      a.href = url;
      a.download = 'ur-dokument-hybrid-audio.html';
      document.body.appendChild(a);
      a.click();
      a.remove();
      URL.revokeObjectURL(url);
    });

    // slides click -> show note in preview
    document.querySelectorAll('.slide').forEach(sl=>{
      sl.addEventListener('click', ()=> {
        const noteEl = sl.querySelector('.notes');
        const fein = noteEl.getAttribute('data-fein') || '';
        const ruppig = noteEl.getAttribute('data-ruppig') || '';
        const tone = document.querySelector('input[name="tone"]:checked').value;
        const txt = (tone === 'ruppig') ? ruppig : fein;
        document.getElementById('notePreview').textContent = txt || 'Keine Notiz';
      });
    });

    // speak and stop
    document.getElementById('speakBtn').addEventListener('click', ()=>{
      const txt = document.getElementById('notePreview').textContent || document.getElementById('refined').textContent;
      if (!txt) { alert('Keine Notiz ausgewählt'); return; }
      speakText(txt);
    });
    document.getElementById('stopSpeak').addEventListener('click', ()=>{ window.speechSynthesis.cancel(); log('Sprechen gestoppt'); });

    // "Mitmachen" guide: will both speak and show alerts and play short harp
    document.getElementById('doItBtn').addEventListener('click', async ()=>{
      await ensureAudio();
      // speak instructions
      const guide = 'Augen schließen. Dreißig Sekunden ruhig atmen. Leise sagen: Alora die Uria – Licht an. Drei bewusste Atemzüge.';
      speakText(guide);
      // short harp after half second
      setTimeout(()=>playHarp(), 600);
      log('Guide gestartet');
    });

    // unlock audio on first user gesture anywhere to reduce confusion
    function userGestureUnlock(){
      if (!audioUnlocked) {
        ensureAudio().then(()=>{ /* nothing */});
      }
      window.removeEventListener('pointerdown', userGestureUnlock);
      window.removeEventListener('keydown', userGestureUnlock);
    }
    window.addEventListener('pointerdown', userGestureUnlock);
    window.addEventListener('keydown', userGestureUnlock);

    // console messages for debugging
    log('Audio‑fähige Seite geladen. Klicke "Audio entsperren" falls nötig.');
  </script>
</body>
</html>
